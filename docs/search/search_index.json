{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to flocky flocky is an open-source platform for development of high quality ReaxFF reactive force fields that is based on the RiPSOGM swarm intelligence algorithm for global optimization 1 . Features Interfaced to a standalone Fortran implementation of tapered ReaxFF 2 MPI support for an asynchronous parallel optimization Flexible parameter space exploration: use of fixed parameter bounds or %change from current values Implicit multi-objective fitness function evaluation by the use of relative weights Training set format supports both finite-size and periodic systems On the fly monitoring of over-fitting during optimization On the fly Bayesian errors analysis for uncertainty quantification Citations 1 David Furman, Benny Carmeli, Yehuda Zeiri and Ronnie Kosloff, \"Enhanced Particle Swarm Optimization Algorithm: Efficient Training of ReaxFF Reactive Force Fields\", J. Chem. Theory Comput. 2018, 14 (6), 3100\u20133112 2 David Furman and David J. Wales, \"Transforming the Accuracy and Numerical Stability of ReaxFF Reactive Force Fields\", J. Phys. Chem. Lett. 2019, 10 (22), 7215-7223","title":"Introduction"},{"location":"#welcome-to-flocky","text":"flocky is an open-source platform for development of high quality ReaxFF reactive force fields that is based on the RiPSOGM swarm intelligence algorithm for global optimization 1 .","title":"Welcome to flocky"},{"location":"#features","text":"Interfaced to a standalone Fortran implementation of tapered ReaxFF 2 MPI support for an asynchronous parallel optimization Flexible parameter space exploration: use of fixed parameter bounds or %change from current values Implicit multi-objective fitness function evaluation by the use of relative weights Training set format supports both finite-size and periodic systems On the fly monitoring of over-fitting during optimization On the fly Bayesian errors analysis for uncertainty quantification","title":"Features"},{"location":"#citations","text":"1 David Furman, Benny Carmeli, Yehuda Zeiri and Ronnie Kosloff, \"Enhanced Particle Swarm Optimization Algorithm: Efficient Training of ReaxFF Reactive Force Fields\", J. Chem. Theory Comput. 2018, 14 (6), 3100\u20133112 2 David Furman and David J. Wales, \"Transforming the Accuracy and Numerical Stability of ReaxFF Reactive Force Fields\", J. Phys. Chem. Lett. 2019, 10 (22), 7215-7223","title":"Citations"},{"location":"examples/","text":"Examples Training of ReaxFF-lg dispersion parameters Accurate description of dispersion interactions in organic crystals is crucial to determine their equilibrium densities 1,2 . In this example, we will be using flocky to search for optimal parameters for the low gradient (lg) model of dispersion 5 . Specifically, we will train the C ij and R ij parameters, starting from arbitrary values in the force field. For the purpose of this demonstration, We will use a minimal training set composed only of the equation of state data of solid benzene, calculated beforehand with a QM level of theory (DFT with TS dispersion correction). Since our system is made up of C and H atoms, we have in total 6 parameters to train (C-C, H-H and C-H interactions for two parameters C ij and R ij ). We will use a swarm size of 10 swarm members and distribute them across 10 CPU cores. Each member will start from a random value for each of the 6 parameters. The necessary files in our run directory are the following: inp_flocky.in - the flocky configuration file. Here we use the following configuration: 1 ! 0: ffield belongs to ReaxFF function 1: ffield belongs to ReaxFF-lg function 0 ! 0: randomize initial positions 1: use current ffield as initial positions 0 ! 0: take position bounds from params.mod file 1: set %change from current ffield positions 0.9 ! percent change from current ffield positions (in case above choice is 1) 0 ! 0: do not detect overfitting 1: detect overfitting 0 ! 0: do not perform UQ 1: perform UQ 10 ! swarm size (integer) 2.0 ! c1 parameter 2.0 ! c2 parameter 0.9 ! w1 parameter 0.4 ! w2 parameter 1 ! fail_i parameter 0.01 ! gamma parameter 1 ! frequency of output 100 ! Max number of optimization iterations per cycle 1 ! Max number of training cycles Note that since we are training a ReaxFF- lg type force field, we should set this explicitly in the first line of our configuration file (=1). Next, we specify that all parameters will have random initial values since we do not have good initial guesses for these parameters in our force field file. For the same reason, the bounds for the parameters will be specified as fixed min and max values in file params.mod . The percent change in this case will be ignored. In addition, we do not activate the optional overfitting and UQ methods (these will be used in an advanced example). The swarm size is set to 10 and the next 5 RiPSOGM global optimization settings will be the default values. The frequency of output will be set to 1 since this demonstration will use only a very modest number of optimization iterations (100). Finally, the number of training cycles will be set to 1. This is sufficient for low-dimensional parameter spaces and when the max number of optimization iterations is large. If the dimensionality of the parameter space is large (> 10), the number of training cycles should be increased as well in order to verify we reach a global optimum. ffield - the ReaxFF- lg force field which will be trained. This is a published force field 3 where the relevant parameters have been set to 0.0000 . paramd.mod - the training parameters specified by their position in the ffield (format: line number, column number, index1, index2, index3, min_bound , max_bound , comment) 50 1 2 1 33 0.1 1000.0 !C_lg C 50 2 2 1 34 1.0 2.00 !R_eq C 55 1 2 2 33 0.1 1000.0 !C_lg H 55 2 2 2 34 1.0 2.00 !R_eq H 120 9 4 1 7 0.0 1000.0 !Off-diagonal C_lg C-H Note that the 3rd, 4th and 5th columns are only for extra book-keeping. They are not required for specification of the parameters but should be included at the moment. Also, the line number should account for any comment/header line in the ffield file. trainset.in - the training set file which defines the cost function to be optimized. The training set file is separated into several sections (CHARGE, CELL PARAMETERS, HEATFO, GEOMETRY, ENERGY). In this demonstration, we will use only energy differences between compressed and expanded crystals of solid benzene, so only the ENERGY/ENDENERGY section will be populated. CHARGE ENDCHARGE CELL PARAMETERS ENDCELL PARAMETERS HEATFO ENDHEATFO GEOMETRY ENDGEOMETRY ENERGY # EOS Benzene 1.0 + Benzene_1.0/1 - Benzene_0.85/1 -1.498 1.0 + Benzene_1.0/1 - Benzene_0.87/1 0.0324 1.0 + Benzene_1.0/1 - Benzene_0.90/1 1.39 1.0 + Benzene_1.0/1 - Benzene_0.93/1 1.82 1.0 + Benzene_1.0/1 - Benzene_0.95/1 1.69 1.0 + Benzene_1.0/1 - Benzene_0.97/1 1.277 1.0 + Benzene_1.0/1 - Benzene_1.02/1 -0.59 1.0 + Benzene_1.0/1 - Benzene_1.05/1 -2.15 1.0 + Benzene_1.0/1 - Benzene_1.07/1 -3.33 1.0 + Benzene_1.0/1 - Benzene_1.1/1 -5.30 ENDENERGY Note that we give equal weights (1.0) to each data point. This is because the energy differences have the same units (kcal/mol) and the same scale (1-10). When using larger training sets with many more data points, it is usually the case that different points have wildly different numerical values (i.e. 0.001 up to 1000). In this case, the use of weights allows us to control the relative contribution of a data point to the total cost function. Thus, in order to increase the influence of a specific data point, we can lower its weight and vice versa. Note The weight controls (and is inversly proportional to) the relative contribution of the data point to the total cost function. Usually, values closer to equilibrium should be given smaller weights in order to make them as important as the far from equilibrium points with larger energy differences. In addition, the weights can be used to compensate for the different scales of different sections (i.e. geometry, charges, energies, etc.) geo - the geometry file containing the coordinates of all the structures in our training set control - the configuration file for ReaxFF (or ReaxFF- lg ) executable. During training the imetho setting should be set to 1 (energy minimization). The target root mean square gradient, specified with the endmm setting should be small enough (< 2.000) to approach an energy minimum (a stationary point). In addition, the maxit setting should be set accordingly. Usually, a setting of 200 is sufficient for small systems.","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/#training-of-reaxff-lg-dispersion-parameters","text":"Accurate description of dispersion interactions in organic crystals is crucial to determine their equilibrium densities 1,2 . In this example, we will be using flocky to search for optimal parameters for the low gradient (lg) model of dispersion 5 . Specifically, we will train the C ij and R ij parameters, starting from arbitrary values in the force field. For the purpose of this demonstration, We will use a minimal training set composed only of the equation of state data of solid benzene, calculated beforehand with a QM level of theory (DFT with TS dispersion correction). Since our system is made up of C and H atoms, we have in total 6 parameters to train (C-C, H-H and C-H interactions for two parameters C ij and R ij ). We will use a swarm size of 10 swarm members and distribute them across 10 CPU cores. Each member will start from a random value for each of the 6 parameters. The necessary files in our run directory are the following: inp_flocky.in - the flocky configuration file. Here we use the following configuration: 1 ! 0: ffield belongs to ReaxFF function 1: ffield belongs to ReaxFF-lg function 0 ! 0: randomize initial positions 1: use current ffield as initial positions 0 ! 0: take position bounds from params.mod file 1: set %change from current ffield positions 0.9 ! percent change from current ffield positions (in case above choice is 1) 0 ! 0: do not detect overfitting 1: detect overfitting 0 ! 0: do not perform UQ 1: perform UQ 10 ! swarm size (integer) 2.0 ! c1 parameter 2.0 ! c2 parameter 0.9 ! w1 parameter 0.4 ! w2 parameter 1 ! fail_i parameter 0.01 ! gamma parameter 1 ! frequency of output 100 ! Max number of optimization iterations per cycle 1 ! Max number of training cycles Note that since we are training a ReaxFF- lg type force field, we should set this explicitly in the first line of our configuration file (=1). Next, we specify that all parameters will have random initial values since we do not have good initial guesses for these parameters in our force field file. For the same reason, the bounds for the parameters will be specified as fixed min and max values in file params.mod . The percent change in this case will be ignored. In addition, we do not activate the optional overfitting and UQ methods (these will be used in an advanced example). The swarm size is set to 10 and the next 5 RiPSOGM global optimization settings will be the default values. The frequency of output will be set to 1 since this demonstration will use only a very modest number of optimization iterations (100). Finally, the number of training cycles will be set to 1. This is sufficient for low-dimensional parameter spaces and when the max number of optimization iterations is large. If the dimensionality of the parameter space is large (> 10), the number of training cycles should be increased as well in order to verify we reach a global optimum. ffield - the ReaxFF- lg force field which will be trained. This is a published force field 3 where the relevant parameters have been set to 0.0000 . paramd.mod - the training parameters specified by their position in the ffield (format: line number, column number, index1, index2, index3, min_bound , max_bound , comment) 50 1 2 1 33 0.1 1000.0 !C_lg C 50 2 2 1 34 1.0 2.00 !R_eq C 55 1 2 2 33 0.1 1000.0 !C_lg H 55 2 2 2 34 1.0 2.00 !R_eq H 120 9 4 1 7 0.0 1000.0 !Off-diagonal C_lg C-H Note that the 3rd, 4th and 5th columns are only for extra book-keeping. They are not required for specification of the parameters but should be included at the moment. Also, the line number should account for any comment/header line in the ffield file. trainset.in - the training set file which defines the cost function to be optimized. The training set file is separated into several sections (CHARGE, CELL PARAMETERS, HEATFO, GEOMETRY, ENERGY). In this demonstration, we will use only energy differences between compressed and expanded crystals of solid benzene, so only the ENERGY/ENDENERGY section will be populated. CHARGE ENDCHARGE CELL PARAMETERS ENDCELL PARAMETERS HEATFO ENDHEATFO GEOMETRY ENDGEOMETRY ENERGY # EOS Benzene 1.0 + Benzene_1.0/1 - Benzene_0.85/1 -1.498 1.0 + Benzene_1.0/1 - Benzene_0.87/1 0.0324 1.0 + Benzene_1.0/1 - Benzene_0.90/1 1.39 1.0 + Benzene_1.0/1 - Benzene_0.93/1 1.82 1.0 + Benzene_1.0/1 - Benzene_0.95/1 1.69 1.0 + Benzene_1.0/1 - Benzene_0.97/1 1.277 1.0 + Benzene_1.0/1 - Benzene_1.02/1 -0.59 1.0 + Benzene_1.0/1 - Benzene_1.05/1 -2.15 1.0 + Benzene_1.0/1 - Benzene_1.07/1 -3.33 1.0 + Benzene_1.0/1 - Benzene_1.1/1 -5.30 ENDENERGY Note that we give equal weights (1.0) to each data point. This is because the energy differences have the same units (kcal/mol) and the same scale (1-10). When using larger training sets with many more data points, it is usually the case that different points have wildly different numerical values (i.e. 0.001 up to 1000). In this case, the use of weights allows us to control the relative contribution of a data point to the total cost function. Thus, in order to increase the influence of a specific data point, we can lower its weight and vice versa. Note The weight controls (and is inversly proportional to) the relative contribution of the data point to the total cost function. Usually, values closer to equilibrium should be given smaller weights in order to make them as important as the far from equilibrium points with larger energy differences. In addition, the weights can be used to compensate for the different scales of different sections (i.e. geometry, charges, energies, etc.) geo - the geometry file containing the coordinates of all the structures in our training set control - the configuration file for ReaxFF (or ReaxFF- lg ) executable. During training the imetho setting should be set to 1 (energy minimization). The target root mean square gradient, specified with the endmm setting should be small enough (< 2.000) to approach an energy minimum (a stationary point). In addition, the maxit setting should be set accordingly. Usually, a setting of 200 is sufficient for small systems.","title":"Training of ReaxFF-lg dispersion parameters"},{"location":"install/","text":"Install flocky Requirements: GCC compiler (tested with 5.4.0 and 7.3.0) OpenMPI (tested with 1.10.2 and 4.0.1) or MPICH2 Boost C++ (tested with 1.70.0) Install procedure: (1) Install OpenMPI or MPICH for parallel execution (for a serial version, skip to step 2): To install mpich type: sudo apt-get install mpich For OpenMPI type: sudo apt-get install openmpi-bin (2) Install Boost C++ required libraries and header files: cd path/to/boost_1_61_0 ./bootstrap.sh --with-libraries=system,filesystem --prefix=path/to/installation/prefix ./b2 install link=static (3) Set your BOOST_LIB_PATH and BOOST_INC_PATH environment variables: export BOOST_LIB_PATH=\"path/to/installation/prefix/lib\" export BOOST_INC_PATH=\"path/to/installation/prefix/include\" (4) Finally, compile flocky (parallel version): make -f Makefile.mpi or a serial version: make -f Makefile.serial","title":"Install flocky"},{"location":"install/#install-flocky","text":"","title":"Install flocky"},{"location":"install/#requirements","text":"GCC compiler (tested with 5.4.0 and 7.3.0) OpenMPI (tested with 1.10.2 and 4.0.1) or MPICH2 Boost C++ (tested with 1.70.0)","title":"Requirements:"},{"location":"install/#install-procedure","text":"(1) Install OpenMPI or MPICH for parallel execution (for a serial version, skip to step 2): To install mpich type: sudo apt-get install mpich For OpenMPI type: sudo apt-get install openmpi-bin (2) Install Boost C++ required libraries and header files: cd path/to/boost_1_61_0 ./bootstrap.sh --with-libraries=system,filesystem --prefix=path/to/installation/prefix ./b2 install link=static (3) Set your BOOST_LIB_PATH and BOOST_INC_PATH environment variables: export BOOST_LIB_PATH=\"path/to/installation/prefix/lib\" export BOOST_INC_PATH=\"path/to/installation/prefix/include\" (4) Finally, compile flocky (parallel version): make -f Makefile.mpi or a serial version: make -f Makefile.serial","title":"Install procedure:"},{"location":"run/","text":"Running flocky Requirements: Running flocky is simple! just launch the appropriate binary ( flocky_mpi or flocky_serial ). Note The number of MPI cores, N, should be less than or equal to the number of swarm agents. To run flocky with MPI parallelization over swarm members, use the corresponding MPI launcher (mpirun or mpiexec) in your system. mpiexec -np N flocky_mpi To run a serial version: flocky_serial","title":"Running flocky"},{"location":"run/#running-flocky","text":"","title":"Running flocky"},{"location":"run/#requirements","text":"Running flocky is simple! just launch the appropriate binary ( flocky_mpi or flocky_serial ). Note The number of MPI cores, N, should be less than or equal to the number of swarm agents. To run flocky with MPI parallelization over swarm members, use the corresponding MPI launcher (mpirun or mpiexec) in your system. mpiexec -np N flocky_mpi To run a serial version: flocky_serial","title":"Requirements:"}]}